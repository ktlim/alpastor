### Welcome to the InfluxDB configuration file.

# Once every 24 hours InfluxDB will report anonymous data to m.influxdb.com
# The data includes raft id (random 8 bytes), os, arch, version, and metadata.
# We don't track ip addresses of servers reporting. This is only used
# to track the number of instances running and the versions, which
# is very helpful for us.
# Change this option to true to disable reporting.
reporting-disabled = false

###
### Enterprise registration control
###

[registration]
# enabled = true
# url = "https://enterprise.influxdata.com" # The Enterprise server URL
# token = "" # Registration token for Enterprise server

###
### [meta]
###
### Controls the parameters for the Raft consensus group that stores metadata
### about the InfluxDB cluster.
###

[meta]
  enabled = true
  dir = "/var/lib/influxdb/meta"
  hostname = "localhost"
  bind-address = ":8088"
  http-bind-address = ":8091"
  https-enabled = false
  https-certificate = ""
  retention-autocreate = true
  election-timeout = "1s"
  heartbeat-timeout = "1s"
  leader-lease-timeout = "500ms"
  commit-timeout = "50ms"
  cluster-tracing = false
  raft-promotion-enabled = true
  logging-enabled = true
  pprof-enabled = false
  lease-duration = "1m0s"

###
### [data]
###
### Controls where the actual shard data for InfluxDB lives and how it is
### flushed from the WAL. "dir" may need to be changed to a suitable place
### for your system, but the WAL settings are an advanced configuration. The
### defaults should work for most systems.
###

[data]
  enabled = true
  dir = "/var/lib/influxdb/data"

  # Controls the engine type for new shards. Options are b1, bz1, or tsm1.
  # b1 is the 0.9.2 storage engine, bz1 is the 0.9.3 and 0.9.4 engine.
  # tsm1 is the 0.9.5 engine and is currenly EXPERIMENTAL. Until 0.9.5 is
  # actually released data written into a tsm1 engine may be need to be wiped
  # between upgrades.
  engine ="tsm1"

  # These are the WAL settings for the storage engine >= 0.9.3
  wal-dir = "/var/lib/influxdb/wal"
  wal-logging-enabled = true

  # Whether queries should be logged before execution. Very useful for troubleshooting, but will
  # log any sensitive data contained within a query.
  query-log-enabled = true

  # The following WAL settings are for the b1 storage engine used in 0.9.2. They won't
  # apply to any new shards created after upgrading to a version > 0.9.3.
  max-wal-size = 104857600 # Maximum size the WAL can reach before a flush. Defaults to 100MB.
  wal-flush-interval = "10m" # Maximum time data can sit in WAL before a flush.
  wal-partition-flush-delay = "2s" # The delay time between each WAL partition being flushed.

  cache-max-memory-size = 524288000
  cache-snapshot-memory-size = 26214400
  cache-snapshot-write-cold-duration = "1h0m0s"
  compact-full-write-cold-duration = "24h0m0s"
  max-points-per-block = 0
  data-logging-enabled = true
  max-series-per-database = 2500000 


###
### [coordinator]
###
### Controls the clustering service configuration.
###

[coordinator]
  write-timeout = "10s"
  max-concurrent-queries = 0
  query-timeout = "0"
  log-queries-after = "0"
  max-select-point = 0
  max-select-series = 0
  max-select-buckets = 0

###
### [retention]
###
### Controls the enforcement of retention policies for evicting old data.
###

[retention]
  enabled = true
  check-interval = "30m"


###
### [shard-precreation]
###
### Controls the precreation of shards, so they are available before data arrives.
### Only shards that, after creation, will have both a start- and end-time in the
### future, will ever be created. Shards are never precreated that would be wholly
### or partially in the past.

[shard-precreation]
  enabled = true
  check-interval = "10m"
  advance-period = "30m"

###
### Controls the system self-monitoring, statistics and diagnostics.
###
### The internal database for monitoring data is created automatically if
### if it does not already exist. The target retention within this database
### is called 'monitor' and is also created with a retention period of 7 days
### and a replication factor of 1, if it does not exist. In all cases the
### this retention policy is configured as the default for the database.

[monitor]
  store-enabled = true # Whether to record statistics internally.
  store-database = "_internal" # The destination database for recorded statistics
  store-interval = "10s" # The interval at which to record statistics


###
### [hinted-handoff]
###
### Controls the hinted handoff feature, which allows nodes to temporarily
### store queued data when one node of a cluster is down for a short period
### of time.
###

[hinted-handoff]
  enabled = true
  dir = "/var/lib/influxdb/hh"
  max-size = 1073741824
  max-age = "168h0m0s"
  retry-rate-limit = 0

  # Hinted handoff will start retrying writes to down nodes at a rate of once per second.
  # If any error occurs, it will backoff in an exponential manner, until the interval
  # reaches retry-max-interval. Once writes to all nodes are successfully completed the
  # interval will reset to retry-interval.
  retry-interval = "1s"
  retry-max-interval = "1m0s"

  # Interval between running checks for data that should be purged. Data is purged from
  # hinted-handoff queues for two reasons. 1) The data is older than the max age, or
  # 2) the target node has been dropped from the cluster. Data is never dropped until
  # it has reached max-age however, for a dropped node or not.
  purge-interval = "1h0m0s"

###
### [admin]
###
### Controls the availability of the built-in, web-based admin interface. If HTTPS is
### enabled for the admin interface, HTTPS must also be enabled on the [http] service.
###

[admin]
  enabled = true
  bind-address = ":8083"
  https-enabled = false
  https-certificate = "/etc/ssl/influxdb.pem"

[subscriber]
  enabled = true
  http-timeout = "30s"


###
### [http]
###
### Controls how the HTTP endpoints are configured. These are the primary
### mechanism for getting data into and out of InfluxDB.
###

[http]
  enabled = true
  bind-address = ":8086"
  auth-enabled = false
  log-enabled = true
  write-tracing = false
  pprof-enabled = false
  https-enabled = false
  https-certificate = "/etc/ssl/influxdb.pem"
  ### Use a separate private key location.
  # https-private-key = ""
  max-row-limit = 0
  realm = "InfluxDB"

###
### [[graphite]]
###
### Controls one or many listeners for Graphite data.
###

[[graphite]]
  enabled = true
  bind-address = ":2003"
  database = "graphite"
  protocol = "tcp"

  consistency-level = "one"
  separator = "."

  # These next lines control how batching works. You should have this enabled
  # otherwise you could get dropped metrics or poor performance. Batching
  # will buffer points in memory if you have many coming in.

  batch-size = 5000 # will flush if this many points get buffered
  batch-pending = 10 # number of batches that may be pending in memory
  batch-timeout = "1s" # will flush at least this often even if we haven't hit buffer limit
  udp-read-buffer = 0 # UDP Read buffer size, 0 means OS default. UDP listener will fail if set above OS max.

  templates = [
    # vmware statsfeeder
     "esxprefix.* .datacenter.type.host.measurement.field",
  ]


###
### [collectd]
###
### Controls the listener for collectd data.
###

[[collectd]]
  enabled = false
  bind-address = ":25826"
  database = "collectd"
  typesdb = "/usr/share/collectd/types.db"

  retention-policy = ""

  # These next lines control how batching works. You should have this enabled
  # otherwise you could get dropped metrics or poor performance. Batching
  # will buffer points in memory if you have many coming in.

  batch-size = 5000 # will flush if this many points get buffered
  batch-pending = 10 # number of batches that may be pending in memory
  batch-timeout = "10s" # will flush at least this often even if we haven't hit buffer limit
  read-buffer = 0 # UDP Read buffer size, 0 means OS default. UDP listener will fail if set above OS max.

###
### [opentsdb]
###
### Controls the listener for OpenTSDB data.
###

[[opentsdb]]
  enabled = true
  bind-address = ":4242"
  database = "opentsdb"
  retention-policy = ""
  consistency-level = "one"
  # tls-enabled = false
  # certificate= ""

  # These next lines control how batching works. You should have this enabled
  # otherwise you could get dropped metrics or poor performance. Only points
  # metrics received over the telnet protocol undergo batching.

  batch-size = 1000 # will flush if this many points get buffered
  batch-pending = 5 # number of batches that may be pending in memory
  batch-timeout = "1s" # will flush at least this often even if we haven't hit buffer limit

###
### [[udp]]
###
### Controls the listeners for InfluxDB line protocol data via UDP.
###

[[udp]]
  enabled = true
  bind-address = ":8086"
  database = "udp"
  # retention-policy = ""

  # These next lines control how batching works. You should have this enabled
  # otherwise you could get dropped metrics or poor performance. Batching
  # will buffer points in memory if you have many coming in.

  batch-size = 1000 # will flush if this many points get buffered
  batch-pending = 5 # number of batches that may be pending in memory
  batch-timeout = "1s" # will flush at least this often even if we haven't hit buffer limit
  read-buffer = 0 # UDP Read buffer size, 0 means OS default. UDP listener will fail if set above OS max.

###
### [continuous_queries]
###
### Controls how continuous queries are run within InfluxDB.
###

[continuous_queries]
  log-enabled = true
  enabled = true
  run-interval = "1s"

